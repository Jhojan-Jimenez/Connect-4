{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6cdb7d2",
   "metadata": {},
   "source": [
    "# Estudio del agente *Magnus* para Connect-4\n",
    "\n",
    "Este notebook (`entrega.ipynb`) contiene el estudio experimental del agente para Connect-4, \n",
    "incluyendo:\n",
    "\n",
    "- Evaluación del agente **Magnus OLD** (versión base) contra un bot aleatorio.\n",
    "- Evaluación del agente **Magnus NEW** (versión con MCTS + Q-learning / tabla Q).\n",
    "- Comparación directa **OLD vs NEW**.\n",
    "- Barrido de hiperparámetros (número de simulaciones) para analizar su efecto en el desempeño.\n",
    "- Generación de gráficas relevantes para la validación y optimización del agente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43596c5",
   "metadata": {},
   "source": [
    "# Notebook de Validación del Agente Magnus\n",
    "Este cuaderno todas las pruebas ralizadas, incluyendo la nueva prueba de **20 partidas contra un bot**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a60ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fcb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from connect4.connect_state import ConnectState\n",
    "from connect4.policy import Policy\n",
    "\n",
    "try:\n",
    "    from groups.Magnus_Old.policy import Aha as MagnusOLD\n",
    "except:\n",
    "    MagnusOLD = None\n",
    "\n",
    "try:\n",
    "    from groups.Magnus_Carlsen.policy import Aha as MagnusNEW\n",
    "except:\n",
    "    MagnusNEW = None\n",
    "\n",
    "class RandomBot(Policy):\n",
    "    def mount(self): pass\n",
    "    def act(self, s):\n",
    "        free = [c for c in range(7) if s[0,c] == 0]\n",
    "        return int(np.random.choice(free)) if free else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc2383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15938b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def play_game(policy_red, policy_yellow):\n",
    "    state = ConnectState()\n",
    "    policy_red.mount()\n",
    "    policy_yellow.mount()\n",
    "\n",
    "    while not state.is_final():\n",
    "        if state.player == -1:\n",
    "            col = policy_red.act(state.board)\n",
    "        else:\n",
    "            col = policy_yellow.act(state.board)\n",
    "        state = state.transition(col)\n",
    "\n",
    "    return state.get_winner()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7d319",
   "metadata": {},
   "source": [
    "## Test: 20 partidas contra RandomBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GAMES = 20\n",
    "results = {}\n",
    "\n",
    "if MagnusOLD:\n",
    "    wins_old = 0\n",
    "    wins_random_old = 0\n",
    "    for i in range(GAMES):\n",
    "        w = play_game(MagnusOLD(simulations=200), RandomBot())\n",
    "        if w == -1:\n",
    "            wins_old += 1\n",
    "        else:\n",
    "            wins_random_old += 1\n",
    "    results[\"OLD\"] = (wins_old, wins_random_old)\n",
    "\n",
    "if MagnusNEW:\n",
    "    wins_new = 0\n",
    "    wins_random_new = 0\n",
    "    for i in range(GAMES):\n",
    "        w = play_game(MagnusNEW(simulations=200), RandomBot())\n",
    "        if w == -1:\n",
    "            wins_new += 1\n",
    "        else:\n",
    "            wins_random_new += 1\n",
    "    results[\"NEW\"] = (wins_new, wins_random_new)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdafbbd",
   "metadata": {},
   "source": [
    "## 1. Configuración del entorno\n",
    "\n",
    "Asegúrate de ejecutar este notebook desde la raíz del proyecto (donde está la carpeta `connect4/` y `groups/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Para que los gráficos se vean dentro del notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Ajustar el path para poder importar los módulos del proyecto\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from connect4.connect_state import ConnectState\n",
    "from connect4.policy import Policy\n",
    "\n",
    "# IMPORTA TUS AGENTES\n",
    "from groups.Magnus_Old.policy import Aha as MagnusOLD\n",
    "from groups.Magnus_Carlsen.policy import AhaSupreme as MagnusNEW  # Ajusta el nombre si cambia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24687f5",
   "metadata": {},
   "source": [
    "## 2. Definición de bots y funciones auxiliares\n",
    "\n",
    "Usaremos un bot aleatorio como rival base y funciones genéricas para simular partidas y torneos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomBot(Policy):\n",
    "    \"\"\"Bot aleatorio que juega cualquier columna disponible.\"\"\"\n",
    "    def mount(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def act(self, s: np.ndarray) -> int:\n",
    "        rng = np.random.default_rng()\n",
    "        available_cols = [c for c in range(7) if s[0, c] == 0]\n",
    "        return int(rng.choice(available_cols))\n",
    "\n",
    "\n",
    "def play_game(policy_red: Policy, policy_yellow: Policy, verbose: bool = False) -> int:\n",
    "    \"\"\"\n",
    "    Simula una partida completa:\n",
    "    - Rojo  = -1 (policy_red)\n",
    "    - Amarillo = +1 (policy_yellow)\n",
    "    Devuelve: -1 si gana rojo, 1 si gana amarillo, 0 empate.\n",
    "    \"\"\"\n",
    "    state = ConnectState()\n",
    "    policy_red.mount()\n",
    "    policy_yellow.mount()\n",
    "\n",
    "    while not state.is_final():\n",
    "        if state.player == -1:\n",
    "            action = policy_red.act(state.board)\n",
    "            if verbose:\n",
    "                print(f\"RED juega {action}\")\n",
    "        else:\n",
    "            action = policy_yellow.act(state.board)\n",
    "            if verbose:\n",
    "                print(f\"YELLOW juega {action}\")\n",
    "\n",
    "        state = state.transition(action)\n",
    "\n",
    "    if verbose:\n",
    "        state.show()\n",
    "\n",
    "    return state.get_winner()\n",
    "\n",
    "\n",
    "def tournament(policy_cls_red, policy_cls_yellow, games: int = 50, simulations_red: int = 200, simulations_yellow: int = 200):\n",
    "    \"\"\"\n",
    "    Ejecuta un mini-torneo entre dos políticas (clases), devolviendo estadísticas.\n",
    "    \"\"\"\n",
    "    results = {\"red\": 0, \"yellow\": 0, \"draw\": 0}\n",
    "\n",
    "    for i in range(games):\n",
    "        # Instanciar políticas (si aceptan parámetro simulations)\n",
    "        try:\n",
    "            red = policy_cls_red(simulations=simulations_red)\n",
    "        except TypeError:\n",
    "            red = policy_cls_red()\n",
    "\n",
    "        try:\n",
    "            yellow = policy_cls_yellow(simulations=simulations_yellow)\n",
    "        except TypeError:\n",
    "            yellow = policy_cls_yellow()\n",
    "\n",
    "        winner = play_game(red, yellow, verbose=False)\n",
    "\n",
    "        if winner == -1:\n",
    "            results[\"red\"] += 1\n",
    "        elif winner == 1:\n",
    "            results[\"yellow\"] += 1\n",
    "        else:\n",
    "            results[\"draw\"] += 1\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582521d8",
   "metadata": {},
   "source": [
    "## 3. Evaluación vs Bot Aleatorio\n",
    "\n",
    "Primero evaluamos cada agente (OLD y NEW) contra un bot aleatorio, \n",
    "para tener una línea base de desempeño.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_vs_random(policy_cls, label: str, games: int = 50, simulations: int = 200):\n",
    "    print(f\"\\n===== {label} vs RandomBot ({games} partidas, simulations={simulations}) =====\")\n",
    "    stats = tournament(policy_cls, RandomBot, games=games, simulations_red=simulations, simulations_yellow=0)\n",
    "    win_rate = stats[\"red\"] / games\n",
    "    loss_rate = stats[\"yellow\"] / games\n",
    "    draw_rate = stats[\"draw\"] / games\n",
    "\n",
    "    print(f\"Ganadas por {label}: {stats['red']} ({win_rate:.3f})\")\n",
    "    print(f\"Ganadas por Random: {stats['yellow']} ({loss_rate:.3f})\")\n",
    "    print(f\"Empates: {stats['draw']} ({draw_rate:.3f})\")\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"games\": games,\n",
    "        \"simulations\": simulations,\n",
    "        \"wins\": stats[\"red\"],\n",
    "        \"losses\": stats[\"yellow\"],\n",
    "        \"draws\": stats[\"draw\"],\n",
    "        \"win_rate\": win_rate,\n",
    "        \"loss_rate\": loss_rate,\n",
    "        \"draw_rate\": draw_rate,\n",
    "    }\n",
    "\n",
    "\n",
    "# Ejemplo rápido (puedes ajustar GAMES y simulations para experimentos más largos)\n",
    "RESULTS_BASE = []\n",
    "\n",
    "RESULTS_BASE.append(eval_vs_random(MagnusOLD, \"Magnus OLD\", games=30, simulations=200))\n",
    "RESULTS_BASE.append(eval_vs_random(MagnusNEW, \"Magnus NEW\", games=30, simulations=200))\n",
    "\n",
    "pd.DataFrame(RESULTS_BASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb878442",
   "metadata": {},
   "source": [
    "## 4. Barrido de hiperparámetros: número de simulaciones\n",
    "\n",
    "Aquí analizamos cómo cambia el desempeño del agente al variar el número de simulaciones\n",
    "por jugada (`simulations`). Esto es clave para la optimización del agente (criterio de la rúbrica).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1427d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_VALUES = [50, 100, 200, 400]\n",
    "GAMES_PER_CONFIG = 20\n",
    "\n",
    "rows = []\n",
    "\n",
    "for sims in SIM_VALUES:\n",
    "    # OLD vs Random\n",
    "    res_old = eval_vs_random(MagnusOLD, \"Magnus OLD\", games=GAMES_PER_CONFIG, simulations=sims)\n",
    "    res_old[\"agent\"] = \"OLD\"\n",
    "    rows.append(res_old)\n",
    "\n",
    "    # NEW vs Random\n",
    "    res_new = eval_vs_random(MagnusNEW, \"Magnus NEW\", games=GAMES_PER_CONFIG, simulations=sims)\n",
    "    res_new[\"agent\"] = \"NEW\"\n",
    "    rows.append(res_new)\n",
    "\n",
    "df_sims = pd.DataFrame(rows)\n",
    "df_sims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a845898f",
   "metadata": {},
   "source": [
    "### 4.1. Gráfica: Win rate vs número de simulaciones\n",
    "\n",
    "Visualizamos la relación entre el número de simulaciones y el porcentaje de victorias\n",
    "para cada agente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for agent in [\"OLD\", \"NEW\"]:\n",
    "    subset = df_sims[df_sims[\"agent\"] == agent]\n",
    "    plt.plot(subset[\"simulations\"], subset[\"win_rate\"], marker=\"o\", label=f\"Magnus {agent}\")\n",
    "\n",
    "plt.xlabel(\"Número de simulaciones por jugada\")\n",
    "plt.ylabel(\"Win rate vs RandomBot\")\n",
    "plt.title(\"Efecto de 'simulations' en el desempeño del agente\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5447a2",
   "metadata": {},
   "source": [
    "## 5. Duelo directo: Magnus OLD vs Magnus NEW\n",
    "\n",
    "Para validar cuál agente es más fuerte de manera relativa, los enfrentamos directamente\n",
    "en ambos roles (rojo y amarillo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3454e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_old_vs_new(games: int = 40, simulations_old: int = 200, simulations_new: int = 200):\n",
    "    results = {\n",
    "        \"OLD_as_RED\": {\"old\": 0, \"new\": 0, \"draw\": 0},\n",
    "        \"NEW_as_RED\": {\"old\": 0, \"new\": 0, \"draw\": 0},\n",
    "    }\n",
    "\n",
    "    # OLD (rojo) vs NEW (amarillo)\n",
    "    for _ in range(games):\n",
    "        old = MagnusOLD(simulations=simulations_old)\n",
    "        new = MagnusNEW(simulations=simulations_new)\n",
    "        winner = play_game(old, new, verbose=False)\n",
    "        if winner == -1:\n",
    "            results[\"OLD_as_RED\"][\"old\"] += 1\n",
    "        elif winner == 1:\n",
    "            results[\"OLD_as_RED\"][\"new\"] += 1\n",
    "        else:\n",
    "            results[\"OLD_as_RED\"][\"draw\"] += 1\n",
    "\n",
    "    # NEW (rojo) vs OLD (amarillo)\n",
    "    for _ in range(games):\n",
    "        old = MagnusOLD(simulations=simulations_old)\n",
    "        new = MagnusNEW(simulations=simulations_new)\n",
    "        winner = play_game(new, old, verbose=False)\n",
    "        if winner == -1:\n",
    "            results[\"NEW_as_RED\"][\"new\"] += 1\n",
    "        elif winner == 1:\n",
    "            results[\"NEW_as_RED\"][\"old\"] += 1\n",
    "        else:\n",
    "            results[\"NEW_as_RED\"][\"draw\"] += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "RESULTS_OLD_NEW = eval_old_vs_new(games=40, simulations_old=200, simulations_new=200)\n",
    "RESULTS_OLD_NEW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los resultados a un DataFrame legible\n",
    "rows = []\n",
    "\n",
    "rows.append({\n",
    "    \"setup\": \"OLD rojo vs NEW amarillo\",\n",
    "    \"wins_old\": RESULTS_OLD_NEW[\"OLD_as_RED\"][\"old\"],\n",
    "    \"wins_new\": RESULTS_OLD_NEW[\"OLD_as_RED\"][\"new\"],\n",
    "    \"draws\": RESULTS_OLD_NEW[\"OLD_as_RED\"][\"draw\"],\n",
    "})\n",
    "\n",
    "rows.append({\n",
    "    \"setup\": \"NEW rojo vs OLD amarillo\",\n",
    "    \"wins_old\": RESULTS_OLD_NEW[\"NEW_as_RED\"][\"old\"],\n",
    "    \"wins_new\": RESULTS_OLD_NEW[\"NEW_as_RED\"][\"new\"],\n",
    "    \"draws\": RESULTS_OLD_NEW[\"NEW_as_RED\"][\"draw\"],\n",
    "})\n",
    "\n",
    "df_old_new = pd.DataFrame(rows)\n",
    "df_old_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica simple de victorias totales OLD vs NEW en el duelo directo\n",
    "total_old = RESULTS_OLD_NEW[\"OLD_as_RED\"][\"old\"] + RESULTS_OLD_NEW[\"NEW_as_RED\"][\"old\"]\n",
    "total_new = RESULTS_OLD_NEW[\"OLD_as_RED\"][\"new\"] + RESULTS_OLD_NEW[\"NEW_as_RED\"][\"new\"]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar([\"Magnus OLD\", \"Magnus NEW\"], [total_old, total_new])\n",
    "plt.ylabel(\"Victorias totales (duelo directo)\")\n",
    "plt.title(\"Duelo directo: OLD vs NEW\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Victorias totales OLD: {total_old}\")\n",
    "print(f\"Victorias totales NEW: {total_new}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f051d5",
   "metadata": {},
   "source": [
    "## 6. Experimentos adicionales y notas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a0eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c03eef3",
   "metadata": {},
   "source": [
    "## 7. Conclusiones preliminares (borrador)\n",
    "\n",
    "- El agente **Magnus OLD** sirve como baseline fuerte basado en MCTS con rollouts aleatorios y heurísticas de victoria/bloqueo inmediato.\n",
    "- El agente **Magnus NEW** incorpora una tabla **Q(s,a)** entrenada por self-play, que actúa como prior en la selección UCB1, mejorando la calidad de las simulaciones en estados ya visitados durante el entrenamiento.\n",
    "- El barrido de `simulations` permite observar el compromiso entre **costo computacional** y **desempeño**: más simulaciones suelen mejorar el win rate, pero con retornos decrecientes.\n",
    "- El duelo directo OLD vs NEW permite validar si el aprendizaje realmente aporta ventaja adicional sobre la versión solo-MCTS.\n",
    "\n",
    "> Ajusta estos puntos según los resultados reales que obtengas al ejecutar el notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
